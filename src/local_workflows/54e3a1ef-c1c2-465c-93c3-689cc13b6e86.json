{
  "description": "FACE MODEL\n==========\nFace models only describe the face. The reference image has to be cut so that only the face is visible.\nAlways use square images. Remember to lower the WEIGHT of the IPAdapter.",
  "name": "IPAdapter Face",
  "stars": "5.0",
  "number_reviews": 0,
  "workflow_like": 31,
  "workflow_view": 22200,
  "workflow_download": 8000,
  "workflow_comment": 4,
  "author_workflow": 33,
  "author_download": 304400,
  "author_like": 936,
  "author_view": 966200,
  "url": "https://openart.ai/workflows/openart/-/XawUsrzeX2ost6XiVtNP",
  "workflow_json": {
    "last_node_id": 21,
    "last_link_id": 33,
    "nodes": [
      {
        "id": 11,
        "type": "VAEDecode",
        "pos": [1300, 170],
        "size": {
          "0": 140,
          "1": 50
        },
        "flags": {},
        "order": 11,
        "mode": 0,
        "inputs": [
          {
            "name": "samples",
            "type": "LATENT",
            "link": 11
          },
          {
            "name": "vae",
            "type": "VAE",
            "link": 12
          }
        ],
        "outputs": [
          {
            "name": "IMAGE",
            "type": "IMAGE",
            "links": [13],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "VAEDecode"
        }
      },
      {
        "id": 12,
        "type": "SaveImage",
        "pos": [1300, 270],
        "size": {
          "0": 400,
          "1": 450
        },
        "flags": {},
        "order": 12,
        "mode": 0,
        "inputs": [
          {
            "name": "images",
            "type": "IMAGE",
            "link": 13
          }
        ],
        "properties": {},
        "widgets_values": ["IPAdapter"]
      },
      {
        "id": 2,
        "type": "VAELoader",
        "pos": [940, 480],
        "size": {
          "0": 300,
          "1": 60
        },
        "flags": {},
        "order": 0,
        "mode": 0,
        "outputs": [
          {
            "name": "VAE",
            "type": "VAE",
            "links": [12],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "VAELoader"
        },
        "widgets_values": ["vae-ft-mse-840000-ema-pruned.safetensors"]
      },
      {
        "id": 7,
        "type": "CLIPTextEncode",
        "pos": [650, 250],
        "size": {
          "0": 210,
          "1": 120
        },
        "flags": {},
        "order": 7,
        "mode": 0,
        "inputs": [
          {
            "name": "clip",
            "type": "CLIP",
            "link": 5
          }
        ],
        "outputs": [
          {
            "name": "CONDITIONING",
            "type": "CONDITIONING",
            "links": [25],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "CLIPTextEncode"
        },
        "widgets_values": ["photo of a guy running"],
        "color": "#232",
        "bgcolor": "#353"
      },
      {
        "id": 8,
        "type": "CLIPTextEncode",
        "pos": [650, 420],
        "size": {
          "0": 210,
          "1": 120
        },
        "flags": {},
        "order": 8,
        "mode": 0,
        "inputs": [
          {
            "name": "clip",
            "type": "CLIP",
            "link": 6
          }
        ],
        "outputs": [
          {
            "name": "CONDITIONING",
            "type": "CONDITIONING",
            "links": [9],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "CLIPTextEncode"
        },
        "widgets_values": ["blurry, horror, distorted, malformed, monochrome"],
        "color": "#322",
        "bgcolor": "#533"
      },
      {
        "id": 10,
        "type": "EmptyLatentImage",
        "pos": [650, 590],
        "size": {
          "0": 210,
          "1": 110
        },
        "flags": {},
        "order": 1,
        "mode": 0,
        "outputs": [
          {
            "name": "LATENT",
            "type": "LATENT",
            "links": [26],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "EmptyLatentImage"
        },
        "widgets_values": [512, 768, 1]
      },
      {
        "id": 19,
        "type": "Note",
        "pos": [44, -146],
        "size": {
          "0": 267.2801513671875,
          "1": 157.0252685546875
        },
        "flags": {},
        "order": 2,
        "mode": 0,
        "properties": {
          "text": ""
        },
        "widgets_values": [
          "FACE MODEL\n==========\n\nFace models only describe the face. The reference image has to be cut so that only the face is visible.\n\nAlways use square images. Remember to lower the WEIGHT of the IPAdapter."
        ],
        "color": "#432",
        "bgcolor": "#653"
      },
      {
        "id": 9,
        "type": "KSampler",
        "pos": [930, 170],
        "size": {
          "0": 315,
          "1": 262
        },
        "flags": {},
        "order": 10,
        "mode": 0,
        "inputs": [
          {
            "name": "model",
            "type": "MODEL",
            "link": 33
          },
          {
            "name": "positive",
            "type": "CONDITIONING",
            "link": 25
          },
          {
            "name": "negative",
            "type": "CONDITIONING",
            "link": 9
          },
          {
            "name": "latent_image",
            "type": "LATENT",
            "link": 26
          }
        ],
        "outputs": [
          {
            "name": "LATENT",
            "type": "LATENT",
            "links": [11],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "KSampler"
        },
        "widgets_values": [33, "fixed", 35, 6, "ddim", "ddim_uniform", 1]
      },
      {
        "id": 4,
        "type": "CLIPVisionLoader",
        "pos": [293, 162],
        "size": {
          "0": 282.7497863769531,
          "1": 63.99153518676758
        },
        "flags": {},
        "order": 3,
        "mode": 0,
        "outputs": [
          {
            "name": "CLIP_VISION",
            "type": "CLIP_VISION",
            "links": [30],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "CLIPVisionLoader"
        },
        "widgets_values": ["IPAdapter_image_encoder_sd15.safetensors"]
      },
      {
        "id": 1,
        "type": "CheckpointLoaderSimple",
        "pos": [290, 280],
        "size": {
          "0": 300,
          "1": 100
        },
        "flags": {},
        "order": 4,
        "mode": 0,
        "outputs": [
          {
            "name": "MODEL",
            "type": "MODEL",
            "links": [31],
            "shape": 3,
            "slot_index": 0
          },
          {
            "name": "CLIP",
            "type": "CLIP",
            "links": [5, 6],
            "shape": 3,
            "slot_index": 1
          },
          {
            "name": "VAE",
            "type": "VAE",
            "links": null,
            "shape": 3
          }
        ],
        "properties": {
          "Node name for S&R": "CheckpointLoaderSimple"
        },
        "widgets_values": ["realisticVisionV51_v51VAE.safetensors"]
      },
      {
        "id": 21,
        "type": "IPAdapterAdvanced",
        "pos": [648, -89],
        "size": {
          "0": 219.76698303222656,
          "1": 278
        },
        "flags": {},
        "order": 9,
        "mode": 0,
        "inputs": [
          {
            "name": "model",
            "type": "MODEL",
            "link": 31
          },
          {
            "name": "ipadapter",
            "type": "IPADAPTER",
            "link": 29
          },
          {
            "name": "image",
            "type": "IMAGE",
            "link": 32
          },
          {
            "name": "image_negative",
            "type": "IMAGE",
            "link": null
          },
          {
            "name": "attn_mask",
            "type": "MASK",
            "link": null
          },
          {
            "name": "clip_vision",
            "type": "CLIP_VISION",
            "link": 30
          }
        ],
        "outputs": [
          {
            "name": "MODEL",
            "type": "MODEL",
            "links": [33],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "IPAdapterAdvanced"
        },
        "widgets_values": [1, "linear", "concat", 0, 1, "V only"]
      },
      {
        "id": 3,
        "type": "IPAdapterModelLoader",
        "pos": [290, 60],
        "size": {
          "0": 293.8300476074219,
          "1": 58
        },
        "flags": {},
        "order": 5,
        "mode": 0,
        "outputs": [
          {
            "name": "IPADAPTER",
            "type": "IPADAPTER",
            "links": [29],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "IPAdapterModelLoader"
        },
        "widgets_values": ["ip-adapter-plus-face_sd15.safetensors"]
      },
      {
        "id": 14,
        "type": "LoadImage",
        "pos": [40, 60],
        "size": {
          "0": 220,
          "1": 320
        },
        "flags": {},
        "order": 6,
        "mode": 0,
        "outputs": [
          {
            "name": "IMAGE",
            "type": "IMAGE",
            "links": [32],
            "shape": 3,
            "slot_index": 0
          },
          {
            "name": "MASK",
            "type": "MASK",
            "links": null,
            "shape": 3
          }
        ],
        "properties": {
          "Node name for S&R": "LoadImage"
        },
        "widgets_values": ["default.jpg", "image"]
      }
    ],
    "links": [
      [5, 1, 1, 7, 0, "CLIP"],
      [6, 1, 1, 8, 0, "CLIP"],
      [9, 8, 0, 9, 2, "CONDITIONING"],
      [11, 9, 0, 11, 0, "LATENT"],
      [12, 2, 0, 11, 1, "VAE"],
      [13, 11, 0, 12, 0, "IMAGE"],
      [25, 7, 0, 9, 1, "CONDITIONING"],
      [26, 10, 0, 9, 3, "LATENT"],
      [29, 3, 0, 21, 1, "IPADAPTER"],
      [30, 4, 0, 21, 5, "CLIP_VISION"],
      [31, 1, 0, 21, 0, "MODEL"],
      [32, 14, 0, 21, 2, "IMAGE"],
      [33, 21, 0, 9, 0, "MODEL"]
    ],
    "groups": [],
    "config": {},
    "extra": {
      "ds": {
        "scale": 1,
        "offset": [-45.7669787424303, 180.3111904440749]
      }
    },
    "version": 0.4
  }
}
