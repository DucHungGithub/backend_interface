{
  "description": "ATTENTION MASKING\n=================\nIPAdapter supports attention masking.\nThe mask determines the area where the IPAdapter will be applied and should have the same size of the final generated image.",
  "name": "IPAdapter Masking",
  "stars": "5.0",
  "number_reviews": 0,
  "workflow_like": 13,
  "workflow_view": 14700,
  "workflow_download": 4600,
  "workflow_comment": 2,
  "author_workflow": 33,
  "author_download": 304400,
  "author_like": 936,
  "author_view": 966200,
  "url": "https://openart.ai/workflows/openart/-/pz0rXAidFCTK2EEmUB1X",
  "workflow_json": {
    "last_node_id": 57,
    "last_link_id": 106,
    "nodes": [
      {
        "id": 5,
        "type": "CLIPTextEncode",
        "pos": [700, 640],
        "size": {
          "0": 400,
          "1": 160
        },
        "flags": {},
        "order": 10,
        "mode": 0,
        "inputs": [
          {
            "name": "clip",
            "type": "CLIP",
            "link": 6
          }
        ],
        "outputs": [
          {
            "name": "CONDITIONING",
            "type": "CONDITIONING",
            "links": [3],
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "CLIPTextEncode"
        },
        "widgets_values": [
          "blurry, malformed, video game, rendering, naked, cleavage, horror, zombie, text, watermark"
        ],
        "color": "#322",
        "bgcolor": "#533"
      },
      {
        "id": 6,
        "type": "VAEDecode",
        "pos": [1510, 400],
        "size": {
          "0": 140,
          "1": 50
        },
        "flags": {},
        "order": 13,
        "mode": 0,
        "inputs": [
          {
            "name": "samples",
            "type": "LATENT",
            "link": 7
          },
          {
            "name": "vae",
            "type": "VAE",
            "link": 8
          }
        ],
        "outputs": [
          {
            "name": "IMAGE",
            "type": "IMAGE",
            "links": [9],
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "VAEDecode"
        }
      },
      {
        "id": 7,
        "type": "VAELoader",
        "pos": [1240, 700],
        "size": {
          "0": 240,
          "1": 60
        },
        "flags": {},
        "order": 0,
        "mode": 0,
        "outputs": [
          {
            "name": "VAE",
            "type": "VAE",
            "links": [8],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "VAELoader"
        },
        "widgets_values": ["vae-ft-mse-840000-ema-pruned.safetensors"]
      },
      {
        "id": 4,
        "type": "CLIPTextEncode",
        "pos": [700, 440],
        "size": {
          "0": 400,
          "1": 160
        },
        "flags": {},
        "order": 9,
        "mode": 0,
        "inputs": [
          {
            "name": "clip",
            "type": "CLIP",
            "link": 5
          }
        ],
        "outputs": [
          {
            "name": "CONDITIONING",
            "type": "CONDITIONING",
            "links": [2],
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "CLIPTextEncode"
        },
        "widgets_values": [
          "photography of a warrior woman in a cherry blossom forest, high quality, highly detailed"
        ],
        "color": "#232",
        "bgcolor": "#353"
      },
      {
        "id": 3,
        "type": "EmptyLatentImage",
        "pos": [890, 850],
        "size": {
          "0": 210,
          "1": 110
        },
        "flags": {},
        "order": 1,
        "mode": 0,
        "outputs": [
          {
            "name": "LATENT",
            "type": "LATENT",
            "links": [4],
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "EmptyLatentImage"
        },
        "widgets_values": [768, 512, 1]
      },
      {
        "id": 1,
        "type": "KSampler",
        "pos": [1240, 400],
        "size": {
          "0": 240,
          "1": 262
        },
        "flags": {},
        "order": 12,
        "mode": 0,
        "inputs": [
          {
            "name": "model",
            "type": "MODEL",
            "link": 105
          },
          {
            "name": "positive",
            "type": "CONDITIONING",
            "link": 2
          },
          {
            "name": "negative",
            "type": "CONDITIONING",
            "link": 3
          },
          {
            "name": "latent_image",
            "type": "LATENT",
            "link": 4
          }
        ],
        "outputs": [
          {
            "name": "LATENT",
            "type": "LATENT",
            "links": [7],
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "KSampler"
        },
        "widgets_values": [40, "fixed", 30, 5, "ddim", "ddim_uniform", 1]
      },
      {
        "id": 8,
        "type": "PreviewImage",
        "pos": [1510, 500],
        "size": {
          "0": 675.9465942382812,
          "1": 480.1444091796875
        },
        "flags": {},
        "order": 14,
        "mode": 0,
        "inputs": [
          {
            "name": "images",
            "type": "IMAGE",
            "link": 9
          }
        ],
        "properties": {
          "Node name for S&R": "PreviewImage"
        }
      },
      {
        "id": 12,
        "type": "LoadImage",
        "pos": [380, 50],
        "size": {
          "0": 230,
          "1": 320
        },
        "flags": {},
        "order": 2,
        "mode": 0,
        "outputs": [
          {
            "name": "IMAGE",
            "type": "IMAGE",
            "links": [32],
            "shape": 3,
            "slot_index": 0
          },
          {
            "name": "MASK",
            "type": "MASK",
            "links": [],
            "shape": 3,
            "slot_index": 1
          }
        ],
        "properties": {
          "Node name for S&R": "LoadImage"
        },
        "widgets_values": ["warrior_woman.png", "image"]
      },
      {
        "id": 55,
        "type": "Note",
        "pos": [1247, 114],
        "size": {
          "0": 230.06593322753906,
          "1": 191.52978515625
        },
        "flags": {},
        "order": 3,
        "mode": 0,
        "properties": {
          "text": ""
        },
        "widgets_values": [
          "ATTENTION MASKING\n=================\n\nIPAdapter supports attention masking.\n\nThe mask determines the area where the IPAdapter will be applied and should have the same size of the final generated image."
        ],
        "color": "#432",
        "bgcolor": "#653"
      },
      {
        "id": 10,
        "type": "IPAdapterModelLoader",
        "pos": [640, 50],
        "size": {
          "0": 300,
          "1": 60
        },
        "flags": {},
        "order": 4,
        "mode": 0,
        "outputs": [
          {
            "name": "IPADAPTER",
            "type": "IPADAPTER",
            "links": [100],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "IPAdapterModelLoader"
        },
        "widgets_values": ["ip-adapter-plus_sd15.safetensors"]
      },
      {
        "id": 11,
        "type": "CLIPVisionLoader",
        "pos": [640, 150],
        "size": {
          "0": 300,
          "1": 60
        },
        "flags": {},
        "order": 5,
        "mode": 0,
        "outputs": [
          {
            "name": "CLIP_VISION",
            "type": "CLIP_VISION",
            "links": [101],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "CLIPVisionLoader"
        },
        "widgets_values": ["IPAdapter_image_encoder_sd15.safetensors"]
      },
      {
        "id": 13,
        "type": "PrepImageForClipVision",
        "pos": [690, 260],
        "size": {
          "0": 243.60000610351562,
          "1": 110
        },
        "flags": {},
        "order": 8,
        "mode": 0,
        "inputs": [
          {
            "name": "image",
            "type": "IMAGE",
            "link": 32
          }
        ],
        "outputs": [
          {
            "name": "IMAGE",
            "type": "IMAGE",
            "links": [102],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "PrepImageForClipVision"
        },
        "widgets_values": ["LANCZOS", "center", 0]
      },
      {
        "id": 2,
        "type": "CheckpointLoaderSimple",
        "pos": [360, 540],
        "size": {
          "0": 290,
          "1": 100
        },
        "flags": {},
        "order": 6,
        "mode": 0,
        "outputs": [
          {
            "name": "MODEL",
            "type": "MODEL",
            "links": [103],
            "slot_index": 0
          },
          {
            "name": "CLIP",
            "type": "CLIP",
            "links": [5, 6],
            "slot_index": 1
          },
          {
            "name": "VAE",
            "type": "VAE",
            "links": [],
            "slot_index": 2
          }
        ],
        "properties": {
          "Node name for S&R": "CheckpointLoaderSimple"
        },
        "widgets_values": ["dreamshaper_8.safetensors"]
      },
      {
        "id": 54,
        "type": "LoadImageMask",
        "pos": [30, 60],
        "size": {
          "0": 315,
          "1": 318
        },
        "flags": {},
        "order": 7,
        "mode": 0,
        "outputs": [
          {
            "name": "MASK",
            "type": "MASK",
            "links": [106],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "LoadImageMask"
        },
        "widgets_values": ["mask (2).png", "red", "image"]
      },
      {
        "id": 57,
        "type": "IPAdapterAdvanced",
        "pos": [986, 79],
        "size": [210, 278],
        "flags": {},
        "order": 11,
        "mode": 0,
        "inputs": [
          {
            "name": "model",
            "type": "MODEL",
            "link": 103
          },
          {
            "name": "ipadapter",
            "type": "IPADAPTER",
            "link": 100
          },
          {
            "name": "image",
            "type": "IMAGE",
            "link": 102
          },
          {
            "name": "image_negative",
            "type": "IMAGE",
            "link": null
          },
          {
            "name": "attn_mask",
            "type": "MASK",
            "link": 106
          },
          {
            "name": "clip_vision",
            "type": "CLIP_VISION",
            "link": 101
          }
        ],
        "outputs": [
          {
            "name": "MODEL",
            "type": "MODEL",
            "links": [105],
            "shape": 3,
            "slot_index": 0
          }
        ],
        "properties": {
          "Node name for S&R": "IPAdapterAdvanced"
        },
        "widgets_values": [
          0.7000000000000001,
          "linear",
          "concat",
          0,
          1,
          "V only"
        ]
      }
    ],
    "links": [
      [2, 4, 0, 1, 1, "CONDITIONING"],
      [3, 5, 0, 1, 2, "CONDITIONING"],
      [4, 3, 0, 1, 3, "LATENT"],
      [5, 2, 1, 4, 0, "CLIP"],
      [6, 2, 1, 5, 0, "CLIP"],
      [7, 1, 0, 6, 0, "LATENT"],
      [8, 7, 0, 6, 1, "VAE"],
      [9, 6, 0, 8, 0, "IMAGE"],
      [32, 12, 0, 13, 0, "IMAGE"],
      [100, 10, 0, 57, 1, "IPADAPTER"],
      [101, 11, 0, 57, 5, "CLIP_VISION"],
      [102, 13, 0, 57, 2, "IMAGE"],
      [103, 2, 0, 57, 0, "MODEL"],
      [105, 57, 0, 1, 0, "MODEL"],
      [106, 54, 0, 57, 4, "MASK"]
    ],
    "groups": [],
    "config": {},
    "extra": {
      "ds": {
        "scale": 1,
        "offset": [-16.900909969522672, 320.04411169244617]
      }
    },
    "version": 0.4
  }
}
